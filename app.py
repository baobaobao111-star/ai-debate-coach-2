import streamlit as st
import google.generativeai as genai
from streamlit_mic_recorder import mic_recorder # ThÆ° viá»‡n ghi Ã¢m má»›i

# --- Cáº¤U HÃŒNH (Thay Key cá»§a báº¡n vÃ o) ---
API_KEY = st.secrets["GEMINI_API_KEY"] 
MODEL_NAME = "gemini-2.5-flash"

st.set_page_config(page_title="AI Debate Master", page_icon="ğŸ¤")
st.title("ğŸ¤ AI Debate Master - Äá»‘i Thá»§ Tranh Biá»‡n")

# Káº¿t ná»‘i Google AI
try:
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)
except Exception as e:
    st.error(f"Lá»—i cáº¥u hÃ¬nh API: {str(e)}")

# --- Bá»˜ NHá»š ---
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.messages.append({
        "role": "model", 
        "content": "ChÃ o báº¡n! TÃ´i Ä‘Ã£ sáºµn sÃ ng. HÃ£y báº¥m nÃºt 'Ghi Ã¢m' bÃªn dÆ°á»›i Ä‘á»ƒ báº¯t Ä‘áº§u tranh biá»‡n!"
    })

# --- THANH CÃ€I Äáº¶T ---
with st.sidebar:
    st.header("âš™ï¸ CÃ i Ä‘áº·t")
    topic = st.text_input("Chá»§ Ä‘á»:", value="NÃªn cáº¥m TikTok")
    side = st.radio("Phe cá»§a báº¡n:", ["á»¦ng há»™", "Pháº£n Ä‘á»‘i"])
    if st.button("ğŸ”„ Reset Tráº­n Ä‘áº¥u"):
        st.session_state.messages = []
        st.rerun()

# --- HIá»‚N THá»Š CHAT ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- HÃ€M Xá»¬ LÃ AI ---
def get_ai_response(user_input, audio_bytes=None):
    system_instruction = f"""
    Báº¡n lÃ  Huáº¥n luyá»‡n viÃªn Tranh biá»‡n Quá»‘c táº¿. Chá»§ Ä‘á»: {topic}. Báº¡n phe Äá»I Láº¬P.
    
    NHIá»†M Vá»¤ Äáº¶C BIá»†T:
    Náº¿u cÃ³ Ã¢m thanh, hÃ£y nghe ká»¹ ngá»¯ Ä‘iá»‡u (run ráº©y hay tá»± tin, cÃ³ nÃ³i láº¯p khÃ´ng).
    
    Cáº¤U TRÃšC TRáº¢ Lá»œI:
    1. ğŸ™ï¸ NHáº¬N XÃ‰T GIá»ŒNG NÃ“I: (Ngáº¯n gá»n vá» Ä‘á»™ tá»± tin/lÆ°u loÃ¡t)
    2. ğŸ›¡ï¸ PHáº¢N BIá»†N LOGIC: (Táº¥n cÃ´ng luáº­n Ä‘iá»ƒm)
    3. ğŸ“Š ÄIá»‚M Sá» (0-10): Logic, Báº±ng chá»©ng, Phong thÃ¡i.
    4. ğŸ¯ CÃ‚U Há»I PHáº¢N BIá»†N Láº I.
    """
    
    chat_session = model.start_chat(history=[])
    try:
        parts = [system_instruction]
        if audio_bytes:
            parts.append({"mime_type": "audio/wav", "data": audio_bytes})
            parts.append("Nghe vÃ  pháº£n biá»‡n.")
        else:
            parts.append(f"Luáº­n Ä‘iá»ƒm: {user_input}")

        response = chat_session.send_message(parts)
        return response.text
    except Exception as e:
        return f"âš ï¸ Lá»—i: {str(e)}"

# --- KHU Vá»°C NHáº¬P LIá»†U ---
st.divider()
col1, col2 = st.columns([1, 3])

with col1:
    st.write("ğŸ”´ **Báº¥m Ä‘á»ƒ nÃ³i:**")
    # NÃºt ghi Ã¢m má»›i: Báº¥m Start Ä‘á»ƒ nÃ³i, Báº¥m Stop Ä‘á»ƒ gá»­i
    audio_data = mic_recorder(
        start_prompt="Báº¯t Ä‘áº§u Ghi Ã¢m",
        stop_prompt="Dá»«ng & Gá»­i",
        key='recorder',
        format="wav" # Quan trá»ng: Gá»­i Ä‘á»‹nh dáº¡ng WAV cho Gemini dá»… Ä‘á»c
    )

# Xá»­ lÃ½ khi cÃ³ file ghi Ã¢m má»›i
if audio_data is not None:
    # Láº¥y dá»¯ liá»‡u bytes
    audio_bytes = audio_data['bytes']
    
    # Kiá»ƒm tra Ä‘á»ƒ trÃ¡nh AI tráº£ lá»i láº·p láº¡i
    # ChÃºng ta dÃ¹ng ID cá»§a file ghi Ã¢m lÃ m dáº¥u má»‘c
    current_audio_id = str(len(audio_bytes)) 
    if st.session_state.get("last_audio_id") != current_audio_id:
        st.session_state.last_audio_id = current_audio_id # LÆ°u dáº¥u má»‘c má»›i
        
        st.chat_message("user").markdown("ğŸ¤ [ÄÃ£ gá»­i Ä‘oáº¡n ghi Ã¢m]")
        st.session_state.messages.append({"role": "user", "content": "ğŸ¤ [ÄÃ£ gá»­i Ä‘oáº¡n ghi Ã¢m]"})
        
        with st.spinner("Äang nghe vÃ  phÃ¢n tÃ­ch..."):
            ai_reply = get_ai_response("", audio_bytes=audio_bytes)
            
        st.chat_message("model").markdown(ai_reply)
        st.session_state.messages.append({"role": "model", "content": ai_reply})
        st.rerun() # LÃ m má»›i trang Ä‘á»ƒ hiá»‡n tin nháº¯n

with col2:
    if prompt := st.chat_input("Hoáº·c nháº­p vÄƒn báº£n táº¡i Ä‘Ã¢y..."):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.spinner("Äang suy nghÄ©..."):
            ai_reply = get_ai_response(prompt)
            
        st.chat_message("model").markdown(ai_reply)
        st.session_state.messages.append({"role": "model", "content": ai_reply})